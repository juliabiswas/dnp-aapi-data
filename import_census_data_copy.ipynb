{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "gYWOXvW-U7rF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba1297ea-d6d7-4471-8170-bdabc82261c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "2C9XiNqiibIG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import statistics\n",
        "import math\n",
        "\n",
        "import requests\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "GoKfe2h2icXU"
      },
      "outputs": [],
      "source": [
        "#constants\n",
        "weight = \"PWGTP\"\n",
        "housing_identifier = \"SERIALNO\"\n",
        "person_identifier = \"SPORDER\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "Dha9-i0uxQ6q"
      },
      "outputs": [],
      "source": [
        "def import_census_data(variables, target, year, limiters, ca_limit): #acs data\n",
        "  '''\n",
        "  limiters: specified values to limit data requested\n",
        "  '''\n",
        "\n",
        "  vars = variables[:]\n",
        "\n",
        "  base_request = \"https://api.census.gov/data/\" + year + \"/acs/acs1/pums?get=\"\n",
        "  base_request += weight + \",\" + target\n",
        "  base_request += \",\" + housing_identifier + \",\" + person_identifier\n",
        "  request = base_request\n",
        "\n",
        "  #remove base vars\n",
        "  vars.remove(target)\n",
        "  vars.remove(weight)\n",
        "  vars.remove(housing_identifier)\n",
        "  vars.remove(person_identifier)\n",
        "\n",
        "  dfs = []\n",
        "\n",
        "  for l in limiters:\n",
        "    request += l\n",
        "\n",
        "    if ca_limit:\n",
        "      request += \"&ucgid=0400000US06\"\n",
        "\n",
        "    #get target/weight/ids\n",
        "    response = requests.get(request)\n",
        "    json_data = json.dumps(response.json())\n",
        "    df = pd.read_json(json_data)\n",
        "    df = df.rename(columns=df.iloc[0]).loc[1:].reset_index()\n",
        "    df = df[[target, weight, housing_identifier, person_identifier]]\n",
        "\n",
        "    dfs.append(df)\n",
        "\n",
        "  data = pd.concat(dfs)\n",
        "\n",
        "  target_col = data[target]\n",
        "  weight_col = data[weight]\n",
        "  housing_identifier_col = data[housing_identifier]\n",
        "  person_identifier_col = data[person_identifier]\n",
        "\n",
        "  #requesting all data\n",
        "  curr = 0\n",
        "  while curr < len(vars):\n",
        "    data, curr = request_vars_and_merge(vars, data, base_request, limiters, target,\n",
        "                                      4, curr, target_col, weight_col,\n",
        "                                      housing_identifier_col, person_identifier_col,\n",
        "                                      ca_limit)\n",
        "\n",
        "  #todo:delete\n",
        "  data.drop([housing_identifier, person_identifier],axis=1,inplace=True)\n",
        "  print(target_corr(data, target, weight))\n",
        "\n",
        "  data.to_csv('data.csv', index=False) #save to csv\n",
        "\n",
        "  return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "V2CZsx5b07nS"
      },
      "outputs": [],
      "source": [
        "def request_vars_and_merge(vars, df, base_request, limiters, target, num_vars, curr,\n",
        "                           target_col, weight_col, housing_identifier_col,\n",
        "                           person_identifier_col, ca_limit):\n",
        "  '''\n",
        "  df: existing df\n",
        "  base_request: request for weight, target, & identifiers\n",
        "  limiter: any limiters on the data requested (e.g. state)\n",
        "  target: target variable\n",
        "  num_vars: vars in base_request\n",
        "  target_col: target var data\n",
        "  weight_col: weights\n",
        "  housing_identifier_col: housing ids\n",
        "  person_identifier_col: person ids within a household\n",
        "  '''\n",
        "\n",
        "  #get new vars\n",
        "  new_df, curr = request_vars(vars, base_request, limiters, target, num_vars,\n",
        "                              curr, weight_col, ca_limit)\n",
        "  new_df.loc[:,target] = target_col\n",
        "  new_df.loc[:,weight] = weight_col\n",
        "  new_df.loc[:,housing_identifier] = housing_identifier_col\n",
        "  new_df.loc[:,person_identifier] = person_identifier_col\n",
        "\n",
        "  new_cols = new_df.columns\n",
        "\n",
        "  #merge with existing df\n",
        "  df = pd.merge(df, new_df, on=[housing_identifier, person_identifier, weight, target])\n",
        "  df.drop_duplicates(keep='first', inplace=True, ignore_index=True)\n",
        "\n",
        "  #pca on whole df (todo)\n",
        "\n",
        "  return df, curr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "KG2UXB1A2wEf"
      },
      "outputs": [],
      "source": [
        "def request_vars(vars, base_request, limiters, target, num_vars, curr,\n",
        "                 weight_col, ca_limit):\n",
        "  #request data\n",
        "  request = base_request\n",
        "\n",
        "  #create requests\n",
        "\n",
        "  while num_vars < 50 and curr < len(vars):\n",
        "    request += ','+vars[curr]\n",
        "    curr += 1\n",
        "    num_vars += 1\n",
        "\n",
        "  dfs = []\n",
        "\n",
        "  for l in limiters:\n",
        "    curr_request = request+ l\n",
        "\n",
        "    if ca_limit:\n",
        "      curr_request += \"&ucgid=0400000US06\"\n",
        "    print(request)\n",
        "\n",
        "    #get target/weight/ids\n",
        "    response = requests.get(curr_request)\n",
        "    json_data = json.dumps(response.json())\n",
        "    df = pd.read_json(json_data)\n",
        "    df = df.rename(columns=df.iloc[0]).loc[1:].reset_index(drop=True)\n",
        "\n",
        "    dfs.append(df)\n",
        "\n",
        "  new_df = pd.concat(dfs)\n",
        "\n",
        "  #drop identifiers\n",
        "  new_df.drop([housing_identifier, person_identifier],axis=1,inplace=True)\n",
        "\n",
        "  #converting N (meaning N/A) to 0, have individually checked each var to confirm this is true\n",
        "  new_df.replace('N', 0, inplace = True)\n",
        "\n",
        "  #indp = based on industry codes, naicsp = based on NAICS codes (indp is\n",
        "  #derived from naicsp and is less detailed to protect individual respondents)\n",
        "  #indp also has higher correlation with income so choosing to keep indp over naicsp\n",
        "  if \"NAICSP\" in new_df.columns:\n",
        "    new_df.drop(\"NAICSP\", axis=1, inplace=True)\n",
        "\n",
        "  #only one unique value, don't need\n",
        "  if \"ADJINC\" in new_df.columns:\n",
        "    new_df.drop(\"ADJINC\", axis=1, inplace=True)\n",
        "  if \"ADJHSG\" in new_df.columns:\n",
        "    new_df.drop(\"ADJHSG\", axis=1, inplace=True)\n",
        "\n",
        "  #recode SOCP\n",
        "  if \"SOCP\" in new_df.columns:\n",
        "    new_df[\"SOCP\"] = recode(new_df, \"SOCP\")\n",
        "\n",
        "  new_df = new_df.astype(int)\n",
        "\n",
        "  #pearson correlation coefficient analysis w target (PINCP)\n",
        "  threshold = 0.2 #todo: change?\n",
        "  correlations = target_corr(new_df, target, weight)\n",
        "  features = correlations[correlations>=threshold]\n",
        "  print(\"selected features:\") #todo:delete\n",
        "  print(features)\n",
        "\n",
        "  #pca (todo)\n",
        "\n",
        "  #fod1p/fod2p have same info but fod2p doesn't have a high enough correlation so already dropped (todo:2x check)\n",
        "\n",
        "  #filter new_df\n",
        "  new_df = new_df[features.index]\n",
        "  return new_df, curr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "-pgxu72DPJfo"
      },
      "outputs": [],
      "source": [
        "def recode(df, col):\n",
        "  '''\n",
        "  returns recoded col\n",
        "  '''\n",
        "  unique = dict(enumerate(df[col].unique()))\n",
        "  unique = dict([(value, key) for key, value in unique.items()])\n",
        "  return df[col].replace(unique)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "BLIGhJBBTR4M"
      },
      "outputs": [],
      "source": [
        "def mean(x, w):\n",
        "  '''weighted mean'''\n",
        "  return np.sum(x.astype(int) * w.astype(int)) / np.sum(w.astype(int))\n",
        "\n",
        "def cov(x, y, w):\n",
        "  '''weighted covariance'''\n",
        "  #return np.sum(w.astype(int) * (x.astype(int) - int(mean(x, w))) * (y.astype(int) - int(mean(y, w)))) / np.sum(w.astype(int))\n",
        "  return np.sum(w * (x.astype(int) - int(mean(x, w))) * (y - mean(y, w))) / np.sum(w)\n",
        "\n",
        "def corr(x, y, w):\n",
        "  '''weighted correlation'''\n",
        "  #return cov(x, y, w) / np.sqrt(cov(x, x, w) * cov(y, y, w))\n",
        "\n",
        "  cov_xy = cov(x, y, w)\n",
        "  cov_xx = cov(x, x, w)\n",
        "  cov_yy = cov(y, y, w)\n",
        "\n",
        "  if np.isclose(cov_xx, 0.0) or np.isclose(cov_yy, 0.0):\n",
        "      print(x)\n",
        "      return 0.0\n",
        "\n",
        "  result = cov_xy / np.sqrt(cov_xx * cov_yy)\n",
        "  return result\n",
        "\n",
        "def target_corr(df, target, weight):\n",
        "  '''\n",
        "  returns new df with index as col names and value as correlation with target\n",
        "  '''\n",
        "  cols = df.columns\n",
        "  cols = cols.drop([target, weight])\n",
        "\n",
        "  l = len(cols)-1\n",
        "  results = []\n",
        "  '''for col in cols:\n",
        "    try:\n",
        "        results.append(corr(df[col], df[target], df[weight]))\n",
        "    except TypeError:\n",
        "        print(df[col])\n",
        "        print(type(df[col]))''';\n",
        "\n",
        "  w = df[weight].astype(int)\n",
        "\n",
        "  for col in cols:\n",
        "    results.append(corr(df[col], df[target], df[weight]))\n",
        "\n",
        "  results = pd.DataFrame(results, index = cols, columns=[\"corr\"])\n",
        "\n",
        "  results = results[\"corr\"].sort_values(ascending=False)[1:]\n",
        "  return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "O7WlIqwW242p"
      },
      "outputs": [],
      "source": [
        "curr_vars = [\"PINCP\", \"PWGTP\", \"SERIALNO\", \"HHLDRAGEP\", \"SSIP\", \"ELEP\", \"RAC2P\",\n",
        "             \"RAC3P\", \"RAC1P\", \"RACNUM\", \"WATP\", \"MHP\", \"RETP\", \"SSP\", \"HINCP\",\n",
        "             \"RMSP\", \"INTP\", \"SEMP\", \"SMP\", \"PERNP\", \"PAP\", \"GASP\", \"WKWN\",\n",
        "             \"WAGP\", \"FULP\", \"SMOCP\", \"FINCP\", \"OIP\", \"TAXAMT\", \"CONP\",\n",
        "             \"INSP\", \"OCPIP\", \"GRNTP\", \"MRGP\", \"VALP\", \"BDSP\", \"NOC\", \"NP\",\n",
        "             \"NRC\", \"SPORDER\", \"NPF\", \"RNTP\", \"WKHP\", \"POVPIP\", \"GRPIP\",\n",
        "             \"JWMNP\", \"AGEP\", \"ADJHSG\", \"ADJINC\", \"MV\", \"FPARC\", \"DRIVESP\",\n",
        "             \"RACSOR\", \"NATIVITY\", \"JWAP\", \"HICOV\", \"PRIVCOV\", \"R60\",\n",
        "             \"RELSHIPP\", \"VACDUR\", \"MLPIK\", \"PLM\", \"VPS\", \"DEAR\", \"R18\", \"MLPJ\",\n",
        "             \"GCL\", \"STOV\", \"TEL\", \"ELEFP\", \"WATFP\", \"YOEP\", \"SMX\", \"OTHSVCEX\",\n",
        "             \"MLPCD\", \"ANC2P\", \"FHINS4C\", \"WRK\", \"POBP\", \"RACAIAN\", \"LAPTOP\",\n",
        "             \"HHT2\", \"MLPFG\", \"FOD1P\", \"FOD2P\", \"SMARTPHONE\", \"NAICSP\", \"INDP\",\n",
        "             \"WAOB\", \"SOCP\", \"GASFP\", \"HIMRKS\", \"FHINS3C\", \"FHINS5C\",\n",
        "             \"ACCESSINET\", \"HOTWAT\", \"NWLA\", \"CITWP\", \"JWTRNS\", \"REFR\", \"PSF\",\n",
        "             \"DECADE\", \"PUBCOV\", \"FULFP\", \"MRGT\", \"VACOTH\", \"BROADBND\", \"LANP\",\n",
        "             \"ANC1P\", \"TEN\", \"POWPUMA\", \"HISPEED\", \"PLMPRP\", \"CPLT\", \"YRBLT\",\n",
        "             \"DRAT\", \"NR\", \"MRGX\", \"HINS7\", \"MARHYP\", \"COMPOTHX\", \"SINK\",\n",
        "             \"MARHT\", \"SATELLITE\", \"WIF\", \"HISP\", \"MAR\", \"SCHL\", \"NWLK\", \"DPHY\",\n",
        "             \"DEYE\", \"MIGSP\", \"HHLANP\", \"PARTNER\", \"RACNH\", \"WKL\", \"VEH\",\n",
        "             \"DDRS\", \"MIGPUMA\", \"LNGI\", \"HINS2\", \"QTRBIR\", \"SFN\", \"RACBLK\",\n",
        "             \"MLPH\", \"ESR\", \"NPP\", \"DIS\", \"DIALUP\", \"HHLDRRAC1P\", \"TABLET\",\n",
        "             \"MLPB\", \"DOUT\", \"SCH\", \"RACPI\", \"POWSP\", \"ANC\", \"MIL\", \"OC\",\n",
        "             \"HUGCL\", \"RWAT\", \"HHLDRHISP\", \"HINS3\", \"RESMODE\", \"MARHW\", \"SFR\",\n",
        "             \"ESP\", \"RACASN\", \"HINS5\", \"MLPE\", \"OCCP\", \"MARHD\", \"SCHG\", \"MRGI\",\n",
        "             \"MIG\", \"HINS1\", \"MSP\", \"FER\", \"MULTG\", \"WORKSTAT\", \"MARHM\", \"KIT\",\n",
        "             \"GCR\", \"HUPARC\", \"HINS6\", \"GCM\", \"ACR\", \"HINS4\", \"PAOC\", \"RNTM\",\n",
        "             \"DRATX\", \"FS\", \"SVAL\", \"RACWHT\", \"NWAB\", \"HUPAOC\", \"R65\", \"RC\",\n",
        "             \"BATH\", \"SEX\", \"HFL\", \"WKEXREL\", \"VACS\", \"HHL\", \"SRNT\", \"NWAV\",\n",
        "             \"NWRE\", \"BLD\", \"LANX\", \"MLPA\", \"HHT\", \"DREM\", \"COW\", \"HUPAC\",\n",
        "             \"CIT\", \"AGS\", \"ENG\", \"JWRIP\", \"JWDP\", \"NOP\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## question 1\n",
        "### for the aapi community, does disaggregating data by ethnicity or by region rather than just by race (aapi + aa/pi) lead to better predictions of someone’s income?"
      ],
      "metadata": {
        "id": "p8TYq9W8mclL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "unTo2cmq29aB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 903
        },
        "outputId": "aacc4221-e0c5-459f-8bc6-96a973055c05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://api.census.gov/data/2021/acs/acs1/pums?get=PWGTP,PINCP,SERIALNO,SPORDER,HHLDRAGEP,SSIP,ELEP,RAC2P,RAC3P,RAC1P,RACNUM,WATP,MHP,RETP,SSP,HINCP,RMSP,INTP,SEMP,SMP,PERNP,PAP,GASP,WKWN,WAGP,FULP,SMOCP,FINCP,OIP,TAXAMT,CONP,INSP,OCPIP,GRNTP,MRGP,VALP,BDSP,NOC,NP,NRC,NPF,RNTP,WKHP,POVPIP,GRPIP,JWMNP,AGEP,ADJHSG,ADJINC,MV\n",
            "https://api.census.gov/data/2021/acs/acs1/pums?get=PWGTP,PINCP,SERIALNO,SPORDER,HHLDRAGEP,SSIP,ELEP,RAC2P,RAC3P,RAC1P,RACNUM,WATP,MHP,RETP,SSP,HINCP,RMSP,INTP,SEMP,SMP,PERNP,PAP,GASP,WKWN,WAGP,FULP,SMOCP,FINCP,OIP,TAXAMT,CONP,INSP,OCPIP,GRNTP,MRGP,VALP,BDSP,NOC,NP,NRC,NPF,RNTP,WKHP,POVPIP,GRPIP,JWMNP,AGEP,ADJHSG,ADJINC,MV\n",
            "https://api.census.gov/data/2021/acs/acs1/pums?get=PWGTP,PINCP,SERIALNO,SPORDER,HHLDRAGEP,SSIP,ELEP,RAC2P,RAC3P,RAC1P,RACNUM,WATP,MHP,RETP,SSP,HINCP,RMSP,INTP,SEMP,SMP,PERNP,PAP,GASP,WKWN,WAGP,FULP,SMOCP,FINCP,OIP,TAXAMT,CONP,INSP,OCPIP,GRNTP,MRGP,VALP,BDSP,NOC,NP,NRC,NPF,RNTP,WKHP,POVPIP,GRPIP,JWMNP,AGEP,ADJHSG,ADJINC,MV\n",
            "0       6\n",
            "1       6\n",
            "2       6\n",
            "3       6\n",
            "4       6\n",
            "       ..\n",
            "1698    6\n",
            "1699    6\n",
            "1700    6\n",
            "1701    6\n",
            "1702    6\n",
            "Name: ST, Length: 79191, dtype: int64\n",
            "selected features:\n",
            "WAGP      0.918188\n",
            "WKHP      0.542990\n",
            "WKWN      0.528609\n",
            "HINCP     0.467163\n",
            "INTP      0.386412\n",
            "FINCP     0.337600\n",
            "POVPIP    0.335686\n",
            "SEMP      0.306281\n",
            "AGEP      0.258930\n",
            "JWMNP     0.204650\n",
            "Name: corr, dtype: float64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-50-2c5804222871>:19: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
            "  new_df.loc[:,target] = target_col\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-b3508f8b3e8f>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#limiters = {\"RACASN\":\"1\", \"RACPI\":\"1\"} #todo:need to figure out how u can do one or the other\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlimiters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"&RACPI=1&RACASN=1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"&RACPI=0&RACASN=1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"&RACPI=1&RACASN=0\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mimport_census_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"PINCP\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"2021\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimiters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-49-59bfb9f84c64>\u001b[0m in \u001b[0;36mimport_census_data\u001b[0;34m(variables, target, year, limiters, ca_limit)\u001b[0m\n\u001b[1;32m     44\u001b[0m   \u001b[0mcurr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0mcurr\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     data, curr = request_vars_and_merge(vars, data, base_request, limiters, target,\n\u001b[0m\u001b[1;32m     47\u001b[0m                                       \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_col\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                                       \u001b[0mhousing_identifier_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperson_identifier_col\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-50-2c5804222871>\u001b[0m in \u001b[0;36mrequest_vars_and_merge\u001b[0;34m(vars, df, base_request, limiters, target, num_vars, curr, target_col, weight_col, housing_identifier_col, person_identifier_col, ca_limit)\u001b[0m\n\u001b[1;32m     17\u001b[0m   new_df, curr = request_vars(vars, base_request, limiters, target, num_vars,\n\u001b[1;32m     18\u001b[0m                               curr, weight_col, ca_limit)\n\u001b[0;32m---> 19\u001b[0;31m   \u001b[0mnew_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_col\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m   \u001b[0mnew_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight_col\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0mnew_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhousing_identifier\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhousing_identifier_col\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0miloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"iloc\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0miloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1726\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_null_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1727\u001b[0m                             \u001b[0;31m# We are setting an entire column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1728\u001b[0;31m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1729\u001b[0m                             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1730\u001b[0m                         \u001b[0;32melif\u001b[0m \u001b[0mis_array_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3978\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3979\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3980\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3982\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4172\u001b[0m         \u001b[0mensure\u001b[0m \u001b[0mhomogeneity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4173\u001b[0m         \"\"\"\n\u001b[0;32m-> 4174\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4176\u001b[0m         if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4910\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_reindex_for_setitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4911\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_dict_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4912\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_reindex_for_setitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4914\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_reindex_for_setitem\u001b[0;34m(value, index)\u001b[0m\n\u001b[1;32m  12023\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  12024\u001b[0m             \u001b[0;31m# duplicate axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 12025\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  12026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  12027\u001b[0m         raise TypeError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_reindex_for_setitem\u001b[0;34m(value, index)\u001b[0m\n\u001b[1;32m  12018\u001b[0m     \u001b[0;31m# GH#4107\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  12019\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 12020\u001b[0;31m         \u001b[0mreindexed_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  12021\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  12022\u001b[0m         \u001b[0;31m# raised in MultiIndex.from_tuples, see test_insert_error_msmgs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mreindex\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5092\u001b[0m                 )\n\u001b[1;32m   5093\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"index\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5094\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5095\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5096\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mreindex\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5288\u001b[0m         \u001b[0;31m# perform the reindex on the axes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5289\u001b[0;31m         return self._reindex_axes(\n\u001b[0m\u001b[1;32m   5290\u001b[0m             \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5291\u001b[0m         ).__finalize__(self, method=\"reindex\")\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_reindex_axes\u001b[0;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[1;32m   5307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5308\u001b[0m             \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5309\u001b[0;31m             obj = obj._reindex_with_indexers(\n\u001b[0m\u001b[1;32m   5310\u001b[0m                 \u001b[0;34m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnew_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5311\u001b[0m                 \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_reindex_with_indexers\u001b[0;34m(self, reindexers, fill_value, copy, allow_dups)\u001b[0m\n\u001b[1;32m   5353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5354\u001b[0m             \u001b[0;31m# TODO: speed up on homogeneous DataFrame objects (see _reindex_multi)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5355\u001b[0;31m             new_data = new_data.reindex_indexer(\n\u001b[0m\u001b[1;32m   5356\u001b[0m                 \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5357\u001b[0m                 \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[1;32m    735\u001b[0m         \u001b[0;31m# some axes don't allow reindexing with dups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_can_reindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_validate_can_reindex\u001b[0;34m(self, indexer)\u001b[0m\n\u001b[1;32m   4314\u001b[0m         \u001b[0;31m# trying to reindex on an axis with duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4315\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_as_unique\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4316\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot reindex on an axis with duplicate labels\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4318\u001b[0m     def reindex(\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reindex on an axis with duplicate labels"
          ]
        }
      ],
      "source": [
        "#limiters = {\"RACASN\":\"1\", \"RACPI\":\"1\", \"ST\":\"0400000US06\"} #limting to CA\n",
        "#limiters = {\"RACASN\":\"1\", \"RACPI\":\"1\"} #todo:need to figure out how u can do one or the other\n",
        "limiters = [\"&RACPI=1&RACASN=1\", \"&RACPI=0&RACASN=1\", \"&RACPI=1&RACASN=0\"]\n",
        "import_census_data(curr_vars, \"PINCP\", \"2021\", limiters, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBbdpmEAAki3"
      },
      "outputs": [],
      "source": [
        "#checking relationship between specific RAC3P (ethnicity) values + income\n",
        "request = \"https://api.census.gov/data/2021/acs/acs1/pums?get=PWGTP,PINCP,SERIALNO,SPORDER&RAC3P=004&RAC3P=006&RAC3P=013\"\n",
        "\n",
        "response = requests.get(request)\n",
        "json_data = json.dumps(response.json())\n",
        "df = pd.read_json(json_data)\n",
        "df = df.rename(columns=df.iloc[0]).loc[1:].reset_index()\n",
        "df.drop([housing_identifier, person_identifier],axis=1,inplace=True)\n",
        "df = df.astype('int32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nxxs790rBUU7"
      },
      "outputs": [],
      "source": [
        "#histogram\n",
        "unique = df['RAC3P'].unique()\n",
        "ethnicities = {6:\"filipino\",4:\"indian\",13:\"samoan\"}\n",
        "\n",
        "for val in unique:\n",
        "  new_df = df[df[\"RAC3P\"] == val]\n",
        "  pyplot.hist(new_df[\"PINCP\"], weights=new_df[\"PWGTP\"], label=ethnicities[val],alpha=.2)\n",
        "\n",
        "pyplot.legend(loc='upper right')\n",
        "pyplot.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## question 2\n",
        "\n",
        "### is it possible to predict race (and potentially, region ethnicity etc) given certain features so even if you don’t give a model race data, can it extrapolate it and build its own stereotypes?"
      ],
      "metadata": {
        "id": "4OJBJs01mo-T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uEpkWV54_cL4"
      },
      "outputs": [],
      "source": [
        "#predict race\n",
        "\n",
        "#todo: could try doing with same dataset as q1 but change output\n",
        "#could also do feature selection again\n",
        "limiters = {\"ST\":\"0400000US06\"} #limting to CA\n",
        "import_census_data(curr_vars, \"RAC1P\", \"2021\", limiters)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}