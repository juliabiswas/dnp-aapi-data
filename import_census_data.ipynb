{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYWOXvW-U7rF"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2C9XiNqiibIG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import statistics\n",
        "import math\n",
        "\n",
        "import requests\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GoKfe2h2icXU"
      },
      "outputs": [],
      "source": [
        "#constants\n",
        "weight = \"PWGTP\"\n",
        "housing_identifier = \"SERIALNO\"\n",
        "person_identifier = \"SPORDER\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dha9-i0uxQ6q"
      },
      "outputs": [],
      "source": [
        "def import_census_data(variables, target, year, limiters): #acs data\n",
        "  '''\n",
        "  limiters: specified values to limit data requested\n",
        "  '''\n",
        "\n",
        "  vars = variables[:]\n",
        "\n",
        "  base_request = \"https://api.census.gov/data/\" + year + \"/acs/acs1/pums?get=\"\n",
        "  base_request += weight + \",\" + target\n",
        "  base_request += \",\" + housing_identifier + \",\" + person_identifier\n",
        "  request = base_request\n",
        "\n",
        "  #limit request\n",
        "  limiter = \"\"\n",
        "  for l in limiters:\n",
        "    if l == \"ST\":\n",
        "      limiter += \"&ucgid=\" + limiters[l]\n",
        "    else:\n",
        "      limiter += \"&\" + l + \"=\" + limiters[l]\n",
        "      if l in vars:\n",
        "        vars.remove(l)\n",
        "  request += limiter\n",
        "\n",
        "  #remove base vars\n",
        "  vars.remove(target)\n",
        "  vars.remove(weight)\n",
        "  vars.remove(housing_identifier)\n",
        "  vars.remove(person_identifier)\n",
        "\n",
        "  #get target/weight/ids\n",
        "  response = requests.get(request)\n",
        "  json_data = json.dumps(response.json())\n",
        "  df = pd.read_json(json_data)\n",
        "  df = df.rename(columns=df.iloc[0]).loc[1:].reset_index()\n",
        "  df = df[[target, weight, housing_identifier, person_identifier]]\n",
        "\n",
        "  target_col = df[target]\n",
        "  weight_col = df[weight]\n",
        "  housing_identifier_col = df[housing_identifier]\n",
        "  person_identifier_col = df[person_identifier]\n",
        "\n",
        "  #requesting all data\n",
        "  curr = 0\n",
        "  while curr < len(vars):\n",
        "    df, curr = request_vars_and_merge(vars, df, base_request, limiter, target,\n",
        "                                      4, curr, target_col, weight_col,\n",
        "                                      housing_identifier_col, person_identifier_col)\n",
        "\n",
        "  #todo:delete\n",
        "  df.drop([housing_identifier, person_identifier],axis=1,inplace=True)\n",
        "  print(target_corr(df, target, weight))\n",
        "\n",
        "  df.to_csv('/content/drive/My Drive/' + target + \"_\" + limiter + \".csv\", index=False) #save to csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2CZsx5b07nS"
      },
      "outputs": [],
      "source": [
        "def request_vars_and_merge(vars, df, base_request, limiter, target, num_vars, curr,\n",
        "                           target_col, weight_col, housing_identifier_col,\n",
        "                           person_identifier_col):\n",
        "  '''\n",
        "  df: existing df\n",
        "  base_request: request for weight, target, & identifiers\n",
        "  limiter: any limiters on the data requested (e.g. state)\n",
        "  target: target variable\n",
        "  num_vars: vars in base_request\n",
        "  target_col: target var data\n",
        "  weight_col: weights\n",
        "  housing_identifier_col: housing ids\n",
        "  person_identifier_col: person ids within a household\n",
        "  '''\n",
        "\n",
        "  #get new vars\n",
        "  new_df, curr = request_vars(vars, base_request, limiter, target, num_vars,\n",
        "                              curr, weight_col)\n",
        "  new_df.loc[:,target] = target_col\n",
        "  new_df.loc[:,weight] = weight_col\n",
        "  new_df.loc[:,housing_identifier] = housing_identifier_col\n",
        "  new_df.loc[:,person_identifier] = person_identifier_col\n",
        "\n",
        "  new_cols = new_df.columns\n",
        "\n",
        "  #merge with existing df\n",
        "  df = pd.merge(df, new_df, on=[housing_identifier, person_identifier, weight, target])\n",
        "  df.drop_duplicates(keep='first', inplace=True, ignore_index=True)\n",
        "\n",
        "  #pca on whole df (todo)\n",
        "\n",
        "  return df, curr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KG2UXB1A2wEf"
      },
      "outputs": [],
      "source": [
        "def request_vars(vars, base_request, limiter, target, num_vars, curr, weight_col):\n",
        "  #request data\n",
        "  request = base_request\n",
        "\n",
        "  #create request\n",
        "  while num_vars < 50 and curr < len(vars):\n",
        "    request += ','+vars[curr]\n",
        "    curr += 1\n",
        "    num_vars += 1\n",
        "  request += limiter\n",
        "\n",
        "  #request\n",
        "  response = requests.get(request)\n",
        "  json_data = json.dumps(response.json())\n",
        "  new_df = pd.read_json(json_data)\n",
        "  new_df = new_df.rename(columns=new_df.iloc[0]).loc[1:].reset_index(drop=True)\n",
        "\n",
        "  #drop non-numeric (can't check correlation & don't need to)\n",
        "  new_df.drop([housing_identifier, person_identifier],axis=1,inplace=True)\n",
        "\n",
        "  #converting N (meaning N/A) to 0, have individually checked each var to confirm this is true\n",
        "  new_df.replace('N', 0, inplace = True)\n",
        "\n",
        "  #indp = based on industry codes, naicsp = based on NAICS codes (indp is\n",
        "  #derived from naicsp and is less detailed to protect individual respondents)\n",
        "  #indp also has higher correlation with income so choosing to keep indp over naicsp\n",
        "  if \"NAICSP\" in new_df.columns:\n",
        "    new_df.drop(\"NAICSP\", axis=1, inplace=True)\n",
        "\n",
        "  #only one unique value, don't need\n",
        "  if \"ADJINC\" in new_df.columns:\n",
        "    new_df.drop(\"ADJINC\", axis=1, inplace=True)\n",
        "\n",
        "  #recode SOCP\n",
        "  if \"SOCP\" in new_df.columns:\n",
        "    new_df[\"SOCP\"] = recode(new_df, \"SOCP\")\n",
        "\n",
        "  new_df = new_df.astype(float)\n",
        "\n",
        "  #pearson correlation coefficient analysis w target (PINCP)\n",
        "  threshold = 0.2 #todo: change?\n",
        "  correlations = target_corr(new_df, target, weight)\n",
        "  features = correlations[correlations>=threshold]\n",
        "  print(\"selected features:\") #todo:delete\n",
        "  print(features)\n",
        "\n",
        "  #pca (todo)\n",
        "\n",
        "  #fod1p/fod2p have same info but fod2p doesn't have a high enough correlation so already dropped (todo:2x check)\n",
        "\n",
        "  #filter new_df\n",
        "  new_df = new_df[features.index]\n",
        "  return new_df, curr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-pgxu72DPJfo"
      },
      "outputs": [],
      "source": [
        "def recode(df, col):\n",
        "  '''\n",
        "  returns recoded col\n",
        "  '''\n",
        "  unique = dict(enumerate(df[col].unique()))\n",
        "  unique = dict([(value, key) for key, value in unique.items()])\n",
        "  return df[col].replace(unique)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLIGhJBBTR4M"
      },
      "outputs": [],
      "source": [
        "def mean(x, w):\n",
        "  '''weighted mean'''\n",
        "  return np.sum(x * w) / np.sum(w)\n",
        "\n",
        "def cov(x, y, w):\n",
        "  '''weighted covariance'''\n",
        "  return np.sum(w * (x - mean(x, w)) * (y - mean(y, w))) / np.sum(w)\n",
        "\n",
        "def corr(x, y, w):\n",
        "  '''weighted correlation'''\n",
        "  #return cov(x, y, w) / np.sqrt(cov(x, x, w) * cov(y, y, w))\n",
        "\n",
        "  cov_xy = cov(x, y, w)\n",
        "  cov_xx = cov(x, x, w)\n",
        "  cov_yy = cov(y, y, w)\n",
        "\n",
        "  if np.isclose(cov_xx, 0.0) or np.isclose(cov_yy, 0.0):\n",
        "      return 0.0  # or handle the zero division case appropriately\n",
        "\n",
        "  if np.any(np.isnan([cov_xy, cov_xx, cov_yy])):\n",
        "      return np.nan  # or handle the case with NaN values\n",
        "\n",
        "  result = cov_xy / np.sqrt(cov_xx * cov_yy)\n",
        "  return result\n",
        "\n",
        "def target_corr(df, target, weight):\n",
        "  '''\n",
        "  returns new df with index as col names and value as correlation with target\n",
        "  '''\n",
        "  cols = df.columns\n",
        "  cols = cols.drop([target, weight])\n",
        "\n",
        "  l = len(cols)-1\n",
        "  results = []\n",
        "  for col in cols:\n",
        "    try:\n",
        "        results.append(corr(df[col], df[target], df[weight]))\n",
        "    except TypeError:\n",
        "        print(col)\n",
        "        print(type(col))\n",
        "        try:\n",
        "            df[col].astype('int32')\n",
        "        except ValueError:\n",
        "            print(col + \" couldn't be casted\")\n",
        "\n",
        "  results = pd.DataFrame(results, index = cols, columns=[\"corr\"])\n",
        "\n",
        "  results = results[\"corr\"].sort_values(ascending=False)[1:]\n",
        "  return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7WlIqwW242p"
      },
      "outputs": [],
      "source": [
        "curr_vars = [\"PINCP\", \"PWGTP\", \"SERIALNO\", \"HHLDRAGEP\", \"SSIP\", \"ELEP\", \"RAC2P\",\n",
        "             \"RAC3P\", \"RAC1P\", \"RACNUM\", \"WATP\", \"MHP\", \"RETP\", \"SSP\", \"HINCP\",\n",
        "             \"RMSP\", \"INTP\", \"SEMP\", \"SMP\", \"PERNP\", \"PAP\", \"GASP\", \"WKWN\",\n",
        "             \"WAGP\", \"FULP\", \"SMOCP\", \"FINCP\", \"OIP\", \"TAXAMT\", \"CONP\",\n",
        "             \"INSP\", \"OCPIP\", \"GRNTP\", \"MRGP\", \"VALP\", \"BDSP\", \"NOC\", \"NP\",\n",
        "             \"NRC\", \"SPORDER\", \"NPF\", \"RNTP\", \"WKHP\", \"POVPIP\", \"GRPIP\",\n",
        "             \"JWMNP\", \"AGEP\", \"ADJHSG\", \"ADJINC\", \"MV\", \"FPARC\", \"DRIVESP\",\n",
        "             \"RACSOR\", \"NATIVITY\", \"JWAP\", \"HICOV\", \"PRIVCOV\", \"R60\",\n",
        "             \"RELSHIPP\", \"VACDUR\", \"MLPIK\", \"PLM\", \"VPS\", \"DEAR\", \"R18\", \"MLPJ\",\n",
        "             \"GCL\", \"STOV\", \"TEL\", \"ELEFP\", \"WATFP\", \"YOEP\", \"SMX\", \"OTHSVCEX\",\n",
        "             \"MLPCD\", \"ANC2P\", \"FHINS4C\", \"WRK\", \"POBP\", \"RACAIAN\", \"LAPTOP\",\n",
        "             \"HHT2\", \"MLPFG\", \"FOD1P\", \"FOD2P\", \"SMARTPHONE\", \"NAICSP\", \"INDP\",\n",
        "             \"WAOB\", \"SOCP\", \"GASFP\", \"HIMRKS\", \"FHINS3C\", \"FHINS5C\",\n",
        "             \"ACCESSINET\", \"HOTWAT\", \"NWLA\", \"CITWP\", \"JWTRNS\", \"REFR\", \"PSF\",\n",
        "             \"DECADE\", \"PUBCOV\", \"FULFP\", \"MRGT\", \"VACOTH\", \"BROADBND\", \"LANP\",\n",
        "             \"ANC1P\", \"TEN\", \"POWPUMA\", \"HISPEED\", \"PLMPRP\", \"CPLT\", \"YRBLT\",\n",
        "             \"DRAT\", \"NR\", \"MRGX\", \"HINS7\", \"MARHYP\", \"COMPOTHX\", \"SINK\",\n",
        "             \"MARHT\", \"SATELLITE\", \"WIF\", \"HISP\", \"MAR\", \"SCHL\", \"NWLK\", \"DPHY\",\n",
        "             \"DEYE\", \"MIGSP\", \"HHLANP\", \"PARTNER\", \"RACNH\", \"WKL\", \"VEH\",\n",
        "             \"DDRS\", \"MIGPUMA\", \"LNGI\", \"HINS2\", \"QTRBIR\", \"SFN\", \"RACBLK\",\n",
        "             \"MLPH\", \"ESR\", \"NPP\", \"DIS\", \"DIALUP\", \"HHLDRRAC1P\", \"TABLET\",\n",
        "             \"MLPB\", \"DOUT\", \"SCH\", \"RACPI\", \"POWSP\", \"ANC\", \"MIL\", \"OC\",\n",
        "             \"HUGCL\", \"RWAT\", \"HHLDRHISP\", \"HINS3\", \"RESMODE\", \"MARHW\", \"SFR\",\n",
        "             \"ESP\", \"RACASN\", \"HINS5\", \"MLPE\", \"OCCP\", \"MARHD\", \"SCHG\", \"MRGI\",\n",
        "             \"MIG\", \"HINS1\", \"MSP\", \"FER\", \"MULTG\", \"WORKSTAT\", \"MARHM\", \"KIT\",\n",
        "             \"GCR\", \"HUPARC\", \"HINS6\", \"GCM\", \"ACR\", \"HINS4\", \"PAOC\", \"RNTM\",\n",
        "             \"DRATX\", \"FS\", \"SVAL\", \"RACWHT\", \"NWAB\", \"HUPAOC\", \"R65\", \"RC\",\n",
        "             \"BATH\", \"SEX\", \"HFL\", \"WKEXREL\", \"VACS\", \"HHL\", \"SRNT\", \"NWAV\",\n",
        "             \"NWRE\", \"BLD\", \"LANX\", \"MLPA\", \"HHT\", \"DREM\", \"COW\", \"HUPAC\",\n",
        "             \"CIT\", \"AGS\", \"ENG\", \"JWRIP\", \"JWDP\", \"NOP\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unTo2cmq29aB"
      },
      "outputs": [],
      "source": [
        "#aapi\n",
        "\n",
        "#do aapi, then asian + pi, then by regions, then by ethnicity\n",
        "\n",
        "#limiters = {\"RACASN\":\"1\", \"RACPI\":\"1\", \"ST\":\"0400000US06\"} #limting to CA\n",
        "#limiters = {\"RAC3P\":\"004\", \"RAC3P\":\"006\", \"RAC3P\":\"013\", \"ST\":\"0400000US06\"} #limting to CA, just indian, filipino & samoan\n",
        "limiters = {\"RACASN\":\"1\", \"RACPI\":\"1\"} #entire U.S.\n",
        "#limiters = {\"ST\":\"0400000US06\"} #all races in CA #todo:check correlation w race\n",
        "import_census_data(curr_vars, \"PINCP\", \"2021\", limiters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBbdpmEAAki3"
      },
      "outputs": [],
      "source": [
        "#checking relationship between specific RAC3P (ethnicity) values + income\n",
        "\n",
        "limiters = {\"RAC3P\":\"006\", \"RAC3P\":\"013\", \"ST\":\"0400000US06\"} #limting to CA, just indian, filipino & samoan\n",
        "request = \"https://api.census.gov/data/2021/acs/acs1/pums?get=PWGTP,PINCP,SERIALNO,SPORDER&RAC3P=004&RAC3P=006&RAC3P=013\"\n",
        "\n",
        "response = requests.get(request)\n",
        "json_data = json.dumps(response.json())\n",
        "df = pd.read_json(json_data)\n",
        "df = df.rename(columns=df.iloc[0]).loc[1:].reset_index()\n",
        "df.drop([housing_identifier, person_identifier],axis=1,inplace=True)\n",
        "df = df.astype('int32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nxxs790rBUU7"
      },
      "outputs": [],
      "source": [
        "#histogram\n",
        "unique = df['RAC3P'].unique()\n",
        "ethnicities = {6:\"filipino\",4:\"indian\",13:\"samoan\"}\n",
        "\n",
        "for val in unique:\n",
        "  new_df = df[df[\"RAC3P\"] == val]\n",
        "  pyplot.hist(new_df[\"PINCP\"], weights=new_df[\"PWGTP\"], label=ethnicities[val],alpha=.2)\n",
        "\n",
        "pyplot.legend(loc='upper right')\n",
        "pyplot.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uEpkWV54_cL4"
      },
      "outputs": [],
      "source": [
        "#predict race\n",
        "limiters = {\"ST\":\"0400000US06\"} #limting to CA\n",
        "import_census_data(curr_vars, \"RAC1P\", \"2021\", limiters)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}