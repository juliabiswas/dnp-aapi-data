{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "gYWOXvW-U7rF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dha9-i0uxQ6q"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "import json\n",
        "\n",
        "weight = \"PWGTP\"\n",
        "housing_identifier = \"SERIALNO\"\n",
        "person_identifier = \"SPORDER\"\n",
        "\n",
        "def import_census_data(vars, target, year, limiters): #acs data\n",
        "  '''\n",
        "  limiters: specified values to limit data requested\n",
        "  '''\n",
        "  curr = 0\n",
        "  base_request = \"https://api.census.gov/data/\" + year + \"/acs/acs1/pums?get=\" + weight + \",\" + target + \",\" + housing_identifier + \",\" + person_identifier\n",
        "  request = base_request\n",
        "\n",
        "  #limit request\n",
        "  limiter = \"\"\n",
        "  for l in limiters:\n",
        "    if l == \"ST\":\n",
        "      limiter += \"&ucgid=\" + limiters[l]\n",
        "    else:\n",
        "      limiter += \"&\" + l + \"=\" + limiters[l]\n",
        "      vars.remove(l)\n",
        "  request += limiter\n",
        "\n",
        "  #remove base vars\n",
        "  vars.remove(target)\n",
        "  vars.remove(weight)\n",
        "  vars.remove(housing_identifier)\n",
        "  vars.remove(person_identifier)\n",
        "\n",
        "  #get target/weight\n",
        "  response = requests.get(request)\n",
        "  json_data = json.dumps(response.json())\n",
        "  df = pd.read_json(json_data)\n",
        "  df = df.rename(columns=df.iloc[0]).loc[1:].reset_index()\n",
        "  df = df[[target, weight, housing_identifier, person_identifier]]\n",
        "\n",
        "  target_col = df[target]\n",
        "  weight_col = df[weight]\n",
        "  housing_identifier_col = df[housing_identifier]\n",
        "  person_identifier_col = df[person_identifier]\n",
        "\n",
        "  #requesting all data\n",
        "  while curr < len(vars):\n",
        "    df, curr = request_vars_and_merge(vars, df, base_request, limiter, target, 4, curr,\n",
        "                                target_col, weight_col, housing_identifier_col,\n",
        "                                person_identifier_col)\n",
        "\n",
        "  #todo:delete\n",
        "  df.drop([housing_identifier, person_identifier],axis=1,inplace=True)\n",
        "  corr = abs(df.corr(method='pearson', numeric_only=False)) #absolute val\n",
        "  target_corr = corr[target].sort_values(ascending=False)[1:]\n",
        "  print(target_corr)\n",
        "\n",
        "  df.to_csv('/content/drive/My Drive/' + target + \"_\" + limiter + \".csv\", index=False) #save to csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def request_vars_and_merge(vars, df, base_request, limiter, target, num_vars, curr,\n",
        "                           target_col, weight_col, housing_identifier_col,\n",
        "                           person_identifier_col):\n",
        "  '''\n",
        "  df: existing df\n",
        "  base_request: request for weight, target, & identifiers\n",
        "  limiter: any limiters on the data requested (e.g. state)\n",
        "  target: target variable\n",
        "  num_vars: vars in base_request\n",
        "  target_col: target var data\n",
        "  weight_col: weights\n",
        "  housing_identifier_col: housing ids\n",
        "  person_identifier_col: person ids within a household\n",
        "  '''\n",
        "\n",
        "  #get new vars\n",
        "  new_df, curr = request_vars(vars, base_request, limiter, target, num_vars, curr)\n",
        "  new_df[target] = target_col\n",
        "  new_df[weight] = weight_col\n",
        "  new_df[housing_identifier] = housing_identifier_col\n",
        "  new_df[person_identifier] = person_identifier_col\n",
        "\n",
        "  new_cols = new_df.columns\n",
        "\n",
        "  #merge with existing df\n",
        "  df = pd.merge(df, new_df, on=[housing_identifier, person_identifier, weight, target])\n",
        "  df.drop_duplicates(keep='first', inplace=True, ignore_index=True)\n",
        "\n",
        "  #pca on whole df (todo)\n",
        "\n",
        "  return df, curr"
      ],
      "metadata": {
        "id": "V2CZsx5b07nS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def request_vars(vars, base_request, limiter, target, num_vars, curr):\n",
        "  #request data\n",
        "  request = base_request\n",
        "\n",
        "  #create request\n",
        "  while num_vars < 50 and curr < len(vars):\n",
        "    request += ','+vars[curr]\n",
        "    curr += 1\n",
        "    num_vars += 1\n",
        "  request += limiter\n",
        "\n",
        "  #request\n",
        "  response = requests.get(request)\n",
        "  json_data = json.dumps(response.json())\n",
        "  new_df = pd.read_json(json_data)\n",
        "  new_df = new_df.rename(columns=new_df.iloc[0]).loc[1:].reset_index(drop=True)\n",
        "\n",
        "  #drop non-numeric (can't check correlation & don't need to)\n",
        "  new_df.drop([housing_identifier, person_identifier],axis=1,inplace=True)\n",
        "\n",
        "  #converting N (meaning N/A) to 0, have individually checked each var to confirm this is true\n",
        "  new_df.replace('N', 0, inplace = True)\n",
        "\n",
        "  #indp = based on industry codes, naicsp = based on NAICS codes (indp is\n",
        "  #derived from naicsp and is less detailed to protect individual respondents)\n",
        "  #indp also has higher correlation with income so choosing to keep indp over naicsp\n",
        "  if \"NAICSP\" in new_df.columns:\n",
        "    new_df.drop(\"NAICSP\", axis=1, inplace=True)\n",
        "\n",
        "  #recode SOCP\n",
        "  if \"SOCP\" in new_df.columns:\n",
        "    new_df[\"SOCP\"] = recode(new_df, \"SOCP\")\n",
        "\n",
        "  #pearson correlation coefficient analysis w target (PINCP)\n",
        "  threshold = 0.2 #todo: change?\n",
        "  corr = abs(new_df.corr(method='pearson', numeric_only=False)) #absolute val\n",
        "  target_corr = corr[target].sort_values(ascending=False)[1:]\n",
        "  features = target_corr[target_corr>=threshold]\n",
        "  print(\"selected features:\") #todo:delete\n",
        "  print(features)\n",
        "\n",
        "  #pca (todo)\n",
        "\n",
        "  #fod1p/fod2p have same info but fod2p doesn't have a high enough correlation so already dropped\n",
        "\n",
        "  #filter new_df\n",
        "  new_df = new_df[features.index]\n",
        "  return new_df, curr"
      ],
      "metadata": {
        "id": "KG2UXB1A2wEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recode(df, col):\n",
        "  '''\n",
        "  returns recoded col\n",
        "  '''\n",
        "  unique = dict(enumerate(df[col].unique()))\n",
        "  unique = dict([(value, key) for key, value in unique.items()])\n",
        "  return df[col].replace(unique)"
      ],
      "metadata": {
        "id": "-pgxu72DPJfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "curr_vars = [\"PINCP\", \"PWGTP\", \"SERIALNO\", \"HHLDRAGEP\", \"SSIP\", \"ELEP\", \"RAC2P\",\n",
        "             \"RAC3P\", \"RAC1P\", \"RACNUM\", \"WATP\", \"MHP\", \"RETP\", \"SSP\", \"HINCP\",\n",
        "             \"RMSP\", \"INTP\", \"SEMP\", \"SMP\", \"PERNP\", \"PAP\", \"GASP\", \"WKWN\",\n",
        "             \"WAGP\", \"FULP\", \"SMOCP\", \"FINCP\", \"OIP\", \"TAXAMT\", \"CONP\",\n",
        "             \"INSP\", \"OCPIP\", \"GRNTP\", \"MRGP\", \"VALP\", \"BDSP\", \"NOC\", \"NP\",\n",
        "             \"NRC\", \"SPORDER\", \"NPF\", \"RNTP\", \"WKHP\", \"POVPIP\", \"GRPIP\",\n",
        "             \"JWMNP\", \"AGEP\", \"ADJHSG\", \"ADJINC\", \"MV\", \"FPARC\", \"DRIVESP\",\n",
        "             \"RACSOR\", \"NATIVITY\", \"JWAP\", \"HICOV\", \"PRIVCOV\", \"R60\",\n",
        "             \"RELSHIPP\", \"VACDUR\", \"MLPIK\", \"PLM\", \"VPS\", \"DEAR\", \"R18\", \"MLPJ\",\n",
        "             \"GCL\", \"STOV\", \"TEL\", \"ELEFP\", \"WATFP\", \"YOEP\", \"SMX\", \"OTHSVCEX\",\n",
        "             \"MLPCD\", \"ANC2P\", \"FHINS4C\", \"WRK\", \"POBP\", \"RACAIAN\", \"LAPTOP\",\n",
        "             \"HHT2\", \"MLPFG\",\n",
        "            \"FOD1P\", \"FOD2P\", \"SMARTPHONE\", \"NAICSP\", \"INDP\", \"WAOB\", \"SOCP\", \"GASFP\", \"HIMRKS\",\n",
        "            \"FHINS3C\", \"FHINS5C\", \"ACCESSINET\", \"HOTWAT\", \"NWLA\", \"CITWP\",\n",
        "            \"JWTRNS\", \"REFR\", \"PSF\", \"DECADE\", \"PUBCOV\", \"FULFP\", \"MRGT\",\n",
        "            \"VACOTH\", \"BROADBND\", \"LANP\", \"ANC1P\", \"TEN\", \"POWPUMA\",\n",
        "            \"HISPEED\", \"PLMPRP\", \"CPLT\", \"YRBLT\", \"DRAT\", \"NR\", \"MRGX\", \"HINS7\",\n",
        "            \"MARHYP\", \"COMPOTHX\", \"SINK\", \"MARHT\", \"SATELLITE\", \"WIF\",\n",
        "            \"HISP\", \"MAR\", \"SCHL\", \"NWLK\", \"DPHY\", \"DEYE\", \"MIGSP\",\n",
        "            \"HHLANP\", \"PARTNER\", \"RACNH\", \"WKL\", \"VEH\", \"DDRS\", \"MIGPUMA\", \"LNGI\",\n",
        "            \"HINS2\", \"QTRBIR\", \"SFN\", \"RACBLK\", \"MLPH\", \"ESR\", \"NPP\", \"DIS\",\n",
        "            \"DIALUP\", \"HHLDRRAC1P\", \"TABLET\", \"MLPB\", \"DOUT\", \"SCH\",\n",
        "            \"RACPI\", \"POWSP\", \"ANC\", \"MIL\", \"OC\", \"HUGCL\", \"RWAT\", \"HHLDRHISP\",\n",
        "            \"HINS3\", \"RESMODE\", \"MARHW\", \"SFR\", \"ESP\", \"RACASN\", \"HINS5\", \"MLPE\",\n",
        "            \"OCCP\", \"MARHD\", \"SCHG\", \"MRGI\", \"MIG\", \"HINS1\", \"MSP\", \"FER\",\n",
        "            \"MULTG\", \"WORKSTAT\", \"MARHM\", \"KIT\", \"GCR\", \"HUPARC\", \"HINS6\",\n",
        "            \"GCM\", \"ACR\", \"HINS4\", \"PAOC\", \"RNTM\", \"DRATX\", \"FS\", \"SVAL\",\n",
        "            \"RACWHT\", \"NWAB\", \"HUPAOC\", \"R65\", \"RC\", \"BATH\", \"SEX\", \"HFL\",\n",
        "            \"WKEXREL\", \"VACS\", \"HHL\", \"SRNT\", \"NWAV\", \"NWRE\", \"BLD\", \"LANX\",\n",
        "            \"MLPA\", \"HHT\", \"DREM\", \"COW\", \"HUPAC\", \"CIT\", \"AGS\", \"ENG\", \"JWRIP\",\n",
        "            \"JWDP\", \"NOP\"]"
      ],
      "metadata": {
        "id": "O7WlIqwW242p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#aapi\n",
        "limiters = {\"RACASN\":\"1\", \"RACPI\":\"1\", \"ST\":\"0400000US06\"} #limting to CA\n",
        "#limiters = {\"RACASN\":\"1\", \"RACPI\":\"1\"} #entire U.S.\n",
        "#limiters = {\"ST\":\"0400000US06\"} #all races in CA #todo:check correlation w race\n",
        "import_census_data(curr_vars, \"PINCP\", \"2021\", limiters)"
      ],
      "metadata": {
        "id": "unTo2cmq29aB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#predict race\n",
        "import_census_data(curr_vars, \"RAC1P\", \"2021\", \"&ucgid=0400000US06\")"
      ],
      "metadata": {
        "id": "uEpkWV54_cL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#income across race\n",
        "'''years = [\"2005\", \"2007\", \"2009\", \"2011\", \"2013\", \"2015\", \"2017\", \"2019\", \"2021\"]\n",
        "#todo:u need to recode NAICSP to INDP (i think hg was helping with that) for this\n",
        "\n",
        "for y in years:\n",
        "  import_census_data(curr_vars, \"PINCP\", y, )''' #need to insert geographies, also probably need a diff vars list bc not all vars every year\n",
        "\n",
        "#there's going to be inflation for income (can compare income buckets)"
      ],
      "metadata": {
        "id": "z4HHJ7qH4kR2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNvAeJI/qyDJfcThtaHXV0Z"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}