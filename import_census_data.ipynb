{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dha9-i0uxQ6q"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "import json\n",
        "\n",
        "def import_census_data(vars, target, year, limiter):\n",
        "  '''\n",
        "  limiter: geographies/years/certain values to be appended to base request\n",
        "  '''\n",
        "  curr = 0\n",
        "  weight = \"PWGTP\"\n",
        "  housing_identifier = \"SERIALNO\"\n",
        "  person_identifier = \"SPORDER\"\n",
        "  base_request = \"https://api.census.gov/data/\" + year + \"/acs/acs1/pums?get=\" + weight + \",\" + target + \",\" + housing_identifier + \",\" + person_identifier\n",
        "  request = base_request + limiter\n",
        "  num_vars = 4\n",
        "  vars.remove(target)\n",
        "  vars.remove(weight)\n",
        "  vars.remove(housing_identifier)\n",
        "  vars.remove(person_identifier)\n",
        "\n",
        "  #get target/weight\n",
        "  print(request)\n",
        "  response = requests.get(request)\n",
        "  json_data = json.dumps(response.json())\n",
        "  df = pd.read_json(json_data)\n",
        "  df = df.rename(columns=df.iloc[0]).loc[1:].reset_index()\n",
        "  df = df[[target, weight, housing_identifier, person_identifier]]\n",
        "  print(df) #todo:delete\n",
        "\n",
        "  target_col = df[target]\n",
        "  weight_col = df[weight]\n",
        "  housing_identifier_col = df[housing_identifier]\n",
        "  person_identifier_col = df[person_identifier]\n",
        "\n",
        "  #requesting all data #todo: make body a func\n",
        "  while curr < len(vars):\n",
        "    request = base_request\n",
        "\n",
        "    #create request\n",
        "    while num_vars < 50:\n",
        "      request += ','+vars[curr]\n",
        "      curr += 1\n",
        "      num_vars += 1\n",
        "      #print(num_vars) #todo:delete\n",
        "    request += limiter\n",
        "\n",
        "    #request data\n",
        "    print(request) #todo:delete\n",
        "    response = requests.get(request)\n",
        "    json_data = json.dumps(response.json())\n",
        "    new_df = pd.read_json(json_data)\n",
        "    new_df = new_df.rename(columns=new_df.iloc[0]).loc[1:].reset_index(drop=True)\n",
        "    print(\"requested data:\")\n",
        "    print(new_df)\n",
        "\n",
        "    #pearson correlation coefficient analysis w target (PINCP)\n",
        "\n",
        "    #deal with problem vars\n",
        "    new_df.drop([housing_identifier, person_identifier],axis=1,inplace=True)\n",
        "    if \"FOD1P\" in new_df.columns:\n",
        "      new_df[\"FOD1P\"] = new_df[\"FOD1P\"].replace('N', 0)\n",
        "    if \"FOD2P\" in new_df.columns:\n",
        "      new_df[\"FOD2P\"] = new_df[\"FOD2P\"].replace('N', 0)\n",
        "    if \"NAICSP\" in new_df.columns: #duplicate of indp\n",
        "      new_df.drop(\"NAICSP\", inplace = True, axis=1)\n",
        "    if \"INDP\" in new_df.columns: #duplicate of indp\n",
        "      new_df[\"INDP\"] = new_df[\"INDP\"].replace('N', 0)\n",
        "    if \"SOCP\" in new_df.columns:\n",
        "      new_df[\"SOCP\"] = recode(new_df, \"SOCP\")\n",
        "\n",
        "    #go thru vars and see what can cast (todo;delete)\n",
        "    for col in new_df.columns:\n",
        "      try:\n",
        "          pd.to_numeric(new_df[col])\n",
        "      except ValueError:\n",
        "          print(col + \" couldn't be casted\")\n",
        "\n",
        "    threshold = 0.5 #todo: change?\n",
        "    corr = abs(new_df.corr(method='pearson', numeric_only=False)) #absolute val\n",
        "\n",
        "    target_corr = corr[target].sort_values(ascending=False)[1:]\n",
        "    features = target_corr[target_corr>=threshold]\n",
        "\n",
        "    #pca (todo)\n",
        "\n",
        "    #filter new_df\n",
        "    new_df = new_df[features.index]\n",
        "    new_df[target] = target_col\n",
        "    new_df[weight] = weight_col\n",
        "    new_df[housing_identifier] = housing_identifier_col\n",
        "    new_df[person_identifier] = person_identifier_col\n",
        "\n",
        "    print(\"with selected features:\")\n",
        "    print(new_df)\n",
        "\n",
        "    #join new_df with existing df\n",
        "    df = pd.merge(df, new_df, on=[housing_identifier, person_identifier, weight, target])\n",
        "    df.drop_duplicates(keep='first', inplace=True, ignore_index=True)\n",
        "    print(\"merged\")\n",
        "    print(df)\n",
        "\n",
        "    #todo:compare FOD1P and FOD2P if they're the exact same just drop but if diff, figure out how to merge\n",
        "\n",
        "    #pca on whole df (todo)\n",
        "\n",
        "    #reset request\n",
        "    request = base_request\n",
        "    num_vars = 4\n",
        "\n",
        "  df.to_csv(target + \"_\" + limiter + \".csv\", sep=',', index=False, encoding='utf-8') #save to csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def recode(df, col):\n",
        "  '''\n",
        "  returns recoded col\n",
        "  '''\n",
        "  unique = dict(enumerate(df[\"SOCP\"].unique()))\n",
        "  unique = dict([(value, key) for key, value in unique.items()])\n",
        "  return df[col].replace(unique)"
      ],
      "metadata": {
        "id": "-pgxu72DPJfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "curr_vars = [\"PINCP\", \"PWGTP\", \"SERIALNO\", \"HHLDRAGEP\", \"SSIP\", \"ELEP\", \"RACNUM\", \"WATP\", \"MHP\", \"RETP\",\n",
        "        \"SSP\", \"HINCP\", \"RMSP\", \"INTP\", \"SEMP\", \"SMP\", \"PERNP\", \"PAP\", \"GASP\",\n",
        "        \"WKWN\", \"WAGP\", \"FULP\", \"SMOCP\", \"FINCP\", \"OIP\", \"TAXAMT\", \"CONP\",\n",
        "        \"INSP\", \"OCPIP\", \"GRNTP\", \"MRGP\", \"VALP\", \"BDSP\", \"NOC\", \"NP\", \"NRC\",\n",
        "        \"SPORDER\", \"NPF\", \"RNTP\", \"WKHP\", \"POVPIP\", \"GRPIP\", \"JWMNP\", \"AGEP\",\n",
        "        \"ADJHSG\", \"ADJINC\", \"MV\", \"FPARC\", \"DRIVESP\", \"RACSOR\",\n",
        "        \"NATIVITY\", \"JWAP\", \"HICOV\", \"PRIVCOV\", \"R60\", \"RELSHIPP\", \"VACDUR\",\n",
        "        \"MLPIK\", \"PLM\", \"VPS\", \"DEAR\", \"R18\", \"MLPJ\", \"GCL\", \"STOV\", \"TEL\",\n",
        "        \"ELEFP\", \"WATFP\", \"YOEP\", \"SMX\", \"OTHSVCEX\", \"MLPCD\", \"ANC2P\",\n",
        "        \"FHINS4C\", \"WRK\", \"POBP\", \"RACAIAN\", \"LAPTOP\", \"HHT2\", \"MLPFG\",\n",
        "        \"FOD1P\", \"SMARTPHONE\", \"NAICSP\", \"WAOB\", \"SOCP\", \"GASFP\", \"HIMRKS\",\n",
        "        \"FHINS3C\", \"FHINS5C\", \"ACCESSINET\", \"HOTWAT\", \"NWLA\", \"CITWP\",\n",
        "        \"JWTRNS\", \"REFR\", \"PSF\", \"DECADE\", \"PUBCOV\", \"FULFP\", \"MRGT\", \"INDP\",\n",
        "        \"VACOTH\", \"FOD2P\", \"BROADBND\", \"LANP\", \"ANC1P\", \"TEN\", \"POWPUMA\",\n",
        "        \"HISPEED\", \"PLMPRP\", \"CPLT\", \"YRBLT\", \"DRAT\", \"NR\", \"MRGX\", \"HINS7\",\n",
        "        \"MARHYP\", \"COMPOTHX\", \"SINK\", \"RAC3P\", \"MARHT\", \"SATELLITE\", \"WIF\",\n",
        "        \"HISP\", \"MAR\", \"SCHL\", \"NWLK\", \"DPHY\", \"DEYE\", \"MIGSP\", \"RAC1P\",\n",
        "        \"HHLANP\", \"PARTNER\", \"RACNH\", \"WKL\", \"VEH\", \"DDRS\", \"MIGPUMA\", \"LNGI\",\n",
        "        \"HINS2\", \"QTRBIR\", \"SFN\", \"RACBLK\", \"MLPH\", \"ESR\", \"NPP\", \"DIS\",\n",
        "        \"DIALUP\", \"HHLDRRAC1P\", \"TABLET\", \"RAC2P\", \"MLPB\", \"DOUT\", \"SCH\",\n",
        "        \"RACPI\", \"POWSP\", \"ANC\", \"MIL\", \"OC\", \"HUGCL\", \"RWAT\", \"HHLDRHISP\",\n",
        "        \"HINS3\", \"RESMODE\", \"MARHW\", \"SFR\", \"ESP\", \"RACASN\", \"HINS5\", \"MLPE\",\n",
        "        \"OCCP\", \"MARHD\", \"SCHG\", \"MRGI\", \"MIG\", \"HINS1\", \"MSP\", \"FER\",\n",
        "        \"MULTG\", \"WORKSTAT\", \"MARHM\", \"KIT\", \"GCR\", \"HUPARC\", \"HINS6\",\n",
        "        \"GCM\", \"ACR\", \"HINS4\", \"PAOC\", \"RNTM\", \"DRATX\", \"FS\", \"SVAL\",\n",
        "        \"RACWHT\", \"NWAB\", \"HUPAOC\", \"R65\", \"RC\", \"BATH\", \"SEX\", \"HFL\",\n",
        "        \"WKEXREL\", \"VACS\", \"HHL\", \"SRNT\", \"NWAV\", \"NWRE\", \"BLD\", \"LANX\",\n",
        "        \"MLPA\", \"HHT\", \"DREM\", \"COW\", \"HUPAC\", \"CIT\", \"AGS\", \"ENG\", \"JWRIP\",\n",
        "        \"JWDP\", \"NOP\"]"
      ],
      "metadata": {
        "id": "O7WlIqwW242p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#aapi\n",
        "import_census_data(curr_vars, \"PINCP\", \"2021\", \"&RACASN=1&RACPI=1&ucgid=0400000US06\") #todo: try limiting not just to CA"
      ],
      "metadata": {
        "id": "unTo2cmq29aB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#predict race\n",
        "import_census_data(curr_vars, \"RAC1P\", \"2021\", \"&ucgid=0400000US06\")"
      ],
      "metadata": {
        "id": "uEpkWV54_cL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#income across race\n",
        "'''years = [\"2005\", \"2007\", \"2009\", \"2011\", \"2013\", \"2015\", \"2017\", \"2019\", \"2021\"]\n",
        "\n",
        "for y in years:\n",
        "  import_census_data(curr_vars, \"PINCP\", y, )''' #need to insert geographies, also probably need a diff vars list bc not all vars every year"
      ],
      "metadata": {
        "id": "z4HHJ7qH4kR2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPzU6H78DByD/FF4EAaPU5x"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}